{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhtaq1frZUzdgR+2uhuNhe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##  Transfer Learning for Flower Species Classification using TensorFlow & Python"
      ],
      "metadata": {
        "id": "66k4xo8HeHbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Import Libraries and Load Dataset:"
      ],
      "metadata": {
        "id": "dQgSm7lGemnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Load the flower dataset from TensorFlow Datasets\n",
        "dataset_name = 'tf_flowers'\n",
        "(ds_train, ds_validation), ds_info = tfds.load(\n",
        "    dataset_name, split=['train[:80%]', 'train[80%:]'],\n",
        "    as_supervised=True, with_info=True\n",
        ")\n",
        "\n",
        "# Print dataset information\n",
        "print(\"Dataset Info:\", ds_info)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzfOPu4hfJQh",
        "outputId": "955714ff-e900-4ee1-fedf-ad17bc6d5340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Info: tfds.core.DatasetInfo(\n",
            "    name='tf_flowers',\n",
            "    full_name='tf_flowers/3.0.1',\n",
            "    description=\"\"\"\n",
            "    A large set of images of flowers\n",
            "    \"\"\",\n",
            "    homepage='https://www.tensorflow.org/tutorials/load_data/images',\n",
            "    data_path='/root/tensorflow_datasets/tf_flowers/3.0.1',\n",
            "    file_format=tfrecord,\n",
            "    download_size=218.21 MiB,\n",
            "    dataset_size=221.83 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=int64, num_classes=5),\n",
            "    }),\n",
            "    supervised_keys=('image', 'label'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'train': <SplitInfo num_examples=3670, num_shards=2>,\n",
            "    },\n",
            "    citation=\"\"\"@ONLINE {tfflowers,\n",
            "    author = \"The TensorFlow Team\",\n",
            "    title = \"Flowers\",\n",
            "    month = \"jan\",\n",
            "    year = \"2019\",\n",
            "    url = \"http://download.tensorflow.org/example_images/flower_photos.tgz\" }\"\"\",\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Preprocess Data and Augmentation:"
      ],
      "metadata": {
        "id": "m9J-MFgmexX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image size and batch size\n",
        "img_size = (299, 299)\n",
        "batch_size = 32\n",
        "\n",
        "# Preprocess function\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, img_size)\n",
        "    image = tf.keras.applications.inception_v3.preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "# Augmentation function\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "# Apply preprocessing and augmentation to training and validation datasets\n",
        "ds_train = ds_train.map(preprocess).map(lambda x, y: (data_augmentation(x, training=True), y)).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "ds_validation = ds_validation.map(preprocess).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "hqgg_Ol4fLzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Load Pretrained InceptionV3 Model:"
      ],
      "metadata": {
        "id": "xc2VXWiYe1w5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained InceptionV3 model with weights from ImageNet\n",
        "base_model = tf.keras.applications.InceptionV3(input_shape=(img_size[0], img_size[1], 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "# Freeze base layers\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "K8QTV9oOgVKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Build and Compile the Transfer Learning Model:\n"
      ],
      "metadata": {
        "id": "4Mpc9g82exeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add custom classification head\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(ds_info.features['label'].num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRXeOeSjgam-",
        "outputId": "71ba7b86-04c0-4f21-894f-97389f06a31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inception_v3 (Functional)   (None, 8, 8, 2048)        21802784  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,854,437\n",
            "Trainable params: 1,051,653\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Train and Evaluate the Model:\n"
      ],
      "metadata": {
        "id": "uaeoQXVZeyZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 10\n",
        "history = model.fit(ds_train, epochs=epochs, validation_data=ds_validation)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(ds_validation)\n",
        "print(f\"Validation loss: {loss:.4f}, Validation accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXoZVoiggh_e",
        "outputId": "e6c2a7a9-51c9-49fa-e4a5-c81d86ef4b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "92/92 [==============================] - 931s 10s/step - loss: 0.8001 - accuracy: 0.7013 - val_loss: 0.3877 - val_accuracy: 0.8692\n",
            "Epoch 2/10\n",
            "92/92 [==============================] - 891s 10s/step - loss: 0.4615 - accuracy: 0.8358 - val_loss: 0.3185 - val_accuracy: 0.9005\n",
            "Epoch 3/10\n",
            "92/92 [==============================] - 897s 10s/step - loss: 0.4120 - accuracy: 0.8522 - val_loss: 0.3145 - val_accuracy: 0.8978\n",
            "Epoch 4/10\n",
            "92/92 [==============================] - 894s 10s/step - loss: 0.3800 - accuracy: 0.8607 - val_loss: 0.2946 - val_accuracy: 0.9019\n",
            "Epoch 5/10\n",
            "92/92 [==============================] - 923s 10s/step - loss: 0.3520 - accuracy: 0.8753 - val_loss: 0.2831 - val_accuracy: 0.9033\n",
            "Epoch 6/10\n",
            "92/92 [==============================] - 923s 10s/step - loss: 0.3169 - accuracy: 0.8876 - val_loss: 0.2940 - val_accuracy: 0.8978\n",
            "Epoch 7/10\n",
            "92/92 [==============================] - 923s 10s/step - loss: 0.3090 - accuracy: 0.8808 - val_loss: 0.2708 - val_accuracy: 0.9046\n",
            "Epoch 8/10\n",
            "92/92 [==============================] - 924s 10s/step - loss: 0.2989 - accuracy: 0.8971 - val_loss: 0.2628 - val_accuracy: 0.9074\n",
            "Epoch 9/10\n",
            "92/92 [==============================] - 922s 10s/step - loss: 0.2850 - accuracy: 0.8975 - val_loss: 0.2496 - val_accuracy: 0.9101\n",
            "Epoch 10/10\n",
            "92/92 [==============================] - 896s 10s/step - loss: 0.2718 - accuracy: 0.8954 - val_loss: 0.3029 - val_accuracy: 0.9033\n",
            "23/23 [==============================] - 174s 8s/step - loss: 0.3029 - accuracy: 0.9033\n",
            "Validation loss: 0.3029, Validation accuracy: 0.9033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jjWDa8vvrO1k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}